{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80a3f271-5a79-4a01-be73-1d6a25036f7c",
   "metadata": {},
   "source": [
    "# run all of the following cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23264cb4-3db1-4752-a576-f751a096c2f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85033caa-fd65-4268-b6c2-7c82b63a6f3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_row(dataframe, fac, comp, sub, eff, num, per, qual):\n",
    "    row_dict = {\"Type\": type_col,\n",
    "                \"Agency\": agency_col,\n",
    "                \"Program\": program_col,\n",
    "                \"Cycle\": cycle_col,\n",
    "                \"Merged\": merged_col,\n",
    "                \"Cycle #\": cycle_num_col,\n",
    "                \"Session Name\": session_name_col,\n",
    "                \"Session #\": session_num_col,\n",
    "                \"End Date\": end_col,\n",
    "                \"Year\": year_col,\n",
    "                \"Quarter\": quarter_col,\n",
    "                \"Format\": format_col,\n",
    "                \"Facilitator\": fac,\n",
    "                \"Component\": comp,\n",
    "                \"Sub Component\": sub,\n",
    "                \"Effectiveness Score\": eff,\n",
    "                \"General #\": num,\n",
    "                \"% Score\": per,\n",
    "                \"Qual\": qual}\n",
    "    dataframe.loc[len(dataframe)] = row_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e888980-328c-40c9-b9d9-25024d70f241",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "replace_values = {\"Not at all effective\":1, \"Slightly effective\":2, \"Somewhat effective\":3, \"Very effective\":4, \"Extremely effective\":5,\n",
    "                 \"Not at all\":1, \"Slightly\":2, \"Somewhat\":3, \"Mostly\":4, \"Completely\":5,\n",
    "                 \"Strongly disagree\":1, \"Disagree\":2, \"Neither agree nor disagree\":3, \"Agree\":4, \"Strongly agree\":5,\n",
    "                 \"Very dissatisfied\":1, \"Somewhat dissatisfied\":2, \"Neither satisfied nor dissatisfied\":3, \"Somewhat satisfied\":4, \"Very satisfied\":5,\n",
    "                 \"Very dissatisfied\":1, \"Somewhat dissatisfied\":2, \"Neither dissatisfied nor satisfied\":3, \"Somewhat satisfied\":4, \"Very satisfied\":5,\n",
    "                 \"Extremely ineffective\":1, \"Ineffective\":2, \"Neither effective nor ineffective\":3, \"Effective\":4, \"Extremely effective\":5,\n",
    "                 \"Extremely dissatisfied\":1, \"Dissatisfied\":2, \"Neither satisfied nor dissatisfied\":3, \"Satisfied\":4, \"Extremely satisfied\":5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e2e98e-b396-4e5f-8a1a-33bd829fb881",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def facilitators(question):\n",
    "    global survey, coaches, coach_idx\n",
    "    for quest in questions:\n",
    "        if question in quest:            \n",
    "            survey = survey.dropna(subset=[quest])\n",
    "            coach_idx = survey.columns.get_loc(quest)\n",
    "            coaches = list(survey[quest].unique())\n",
    "            count = pd.Series(survey[quest].value_counts())\n",
    "            percent = pd.Series(survey[quest].value_counts(normalize=True))\n",
    "            for row in range(len(percent)):\n",
    "                add_row(df, count.index[row], \"Responses % of Total\", \"\", \"\", int(count.iloc[row]),\n",
    "                str(int(round(float(percent.iloc[row]), 2) * 100)) + \"%\", \"\")\n",
    "                \n",
    "def application_score(question):\n",
    "    for quest in questions:\n",
    "        if question in quest:\n",
    "            application_idx = survey.columns.get_loc(quest)\n",
    "            if coaches:\n",
    "                for coach in coaches:\n",
    "                    application_count = pd.Series(survey[survey[questions[coach_idx]] == coach][quest].value_counts(normalize=True))\n",
    "                    add_row(df, coach, \"Application\", \"\", \"\", \"\", str(int(round(float(application_count.loc[\"Yes\"]), 2) * 100)) + \"%\", \"\")                                  \n",
    "                \n",
    "def application_qual_comm(question):\n",
    "    for quest in questions:\n",
    "        if question in quest:\n",
    "            application_qual_idx = survey.columns.get_loc(quest)\n",
    "            if coaches:\n",
    "                for coach in coaches:\n",
    "                    application_qual = pd.Series(survey[survey[questions[coach_idx]] == coach][questions[application_qual_idx]], dtype=\"string\")\n",
    "                    application_qual = application_qual.dropna()\n",
    "                    for row in range(len(application_qual)):\n",
    "                        add_row(df, coach, \"Application Qual\", \"\", \"\", \"\", \"\", application_qual.iloc[row]) \n",
    "                        \n",
    "def application_qual_barr_comm(question):\n",
    "    for quest in questions:\n",
    "        if question in quest:\n",
    "            application_qual_barr_idx = survey.columns.get_loc(quest)\n",
    "            if coaches:\n",
    "                for coach in coaches:\n",
    "                    application_qual_barr = pd.Series(survey[survey[questions[coach_idx]] == coach][questions[application_qual_barr_idx]], dtype=\"string\")\n",
    "                    application_qual_barr = application_qual_barr.dropna()\n",
    "                    for row in range(len(application_qual_barr)):\n",
    "                        add_row(df, coach, \"Application Barriers Qual\", \"\", \"\", \"\", \"\", application_qual_barr.iloc[row])         \n",
    "                        \n",
    "def objectives(question):\n",
    "    global survey\n",
    "    for quest in questions:\n",
    "        if question in quest:\n",
    "            objective_idx = survey.columns.get_loc(quest)\n",
    "            survey = survey.replace({quest:replace_values})\n",
    "            if coaches:\n",
    "                for coach in coaches:\n",
    "                    objective_score = pd.Series(survey[survey[questions[coach_idx]] == coach][questions[objective_idx]], dtype=\"float\")\n",
    "                    add_row(df, coach, \"Objective\", quest[len(question):], round(objective_score.mean(), 2), \"\", \"\", \"\")                        \n",
    "                        \n",
    "def prework(question):\n",
    "    global survey\n",
    "    for quest in questions:\n",
    "        if question in quest:\n",
    "            prework_idx = survey.columns.get_loc(quest)\n",
    "            survey = survey.replace({quest:replace_values})\n",
    "            if coaches:\n",
    "                for coach in coaches:\n",
    "                    prework_score = pd.Series(survey[survey[questions[coach_idx]] == coach][questions[prework_idx]], dtype=\"float\")\n",
    "                    add_row(df, coach, \"Pre-Work\", quest[len(question):], round(prework_score.mean(), 2), \"\", \"\", \"\")                        \n",
    "                                                \n",
    "def improvement_qual_comm(question):\n",
    "    for quest in questions:\n",
    "        if question in quest:\n",
    "            improvement_qual_idx = survey.columns.get_loc(quest)\n",
    "            if coaches:\n",
    "                for coach in coaches:\n",
    "                    improvement_qual = pd.Series(survey[survey[questions[coach_idx]] == coach][questions[improvement_qual_idx]], dtype=\"string\")\n",
    "                    improvement_qual = improvement_qual.dropna()\n",
    "                    for row in range(len(improvement_qual)):\n",
    "                        add_row(df, coach, \"Improvement Qual\", \"\", \"\", \"\", \"\", improvement_qual.iloc[row])                         \n",
    "                        \n",
    "def facilitator_effectiveness(question):\n",
    "    global survey\n",
    "    for quest in questions:\n",
    "        if question in quest:\n",
    "            facilitator_idx = survey.columns.get_loc(quest)\n",
    "            survey = survey.replace({quest:replace_values})\n",
    "            if coaches:\n",
    "                for coach in coaches:\n",
    "                    facilitator_score = pd.Series(survey[survey[questions[coach_idx]] == coach][questions[facilitator_idx]], dtype=\"float\")\n",
    "                    add_row(df, coach, \"Facilitator Effectiveness\", quest[len(question):], round(facilitator_score.mean(), 2), \"\", \"\", \"\")                        \n",
    "                        \n",
    "def facilitator_qual_comm(question):\n",
    "    for quest in questions:\n",
    "        if question in quest:\n",
    "            facilitator_qual_idx = survey.columns.get_loc(quest)\n",
    "            if coaches:\n",
    "                for coach in coaches:\n",
    "                    facilitator_qual = pd.Series(survey[survey[questions[coach_idx]] == coach][questions[facilitator_qual_idx]], dtype=\"string\")\n",
    "                    facilitator_qual = facilitator_qual.dropna()\n",
    "                    for row in range(len(facilitator_qual)):\n",
    "                        add_row(df, coach, \"Facilitator Qual\", \"\", \"\", \"\", \"\", facilitator_qual.iloc[row])                         \n",
    "                        \n",
    "def connections(question):      \n",
    "    global survey\n",
    "    for quest in questions:\n",
    "        if question in quest:\n",
    "            connections_idx = survey.columns.get_loc(quest)\n",
    "            survey = survey.replace({quest:replace_values})\n",
    "            if coaches:\n",
    "                for coach in coaches:\n",
    "                    connections_score = pd.Series(survey[survey[questions[coach_idx]] == coach][questions[connections_idx]], dtype=\"float\")\n",
    "                    add_row(df, coach, \"Prof. Connections\", \"\", round(connections_score.mean(), 2), \"\", \"\", \"\")\n",
    "                               \n",
    "def additional_qual_comm(question):\n",
    "    for quest in questions:\n",
    "        if question in quest:\n",
    "            additional_qual_idx = survey.columns.get_loc(quest)\n",
    "            if coaches:\n",
    "                for coach in coaches:\n",
    "                    additional_qual = pd.Series(survey[survey[questions[coach_idx]] == coach][questions[additional_qual_idx]], dtype=\"string\")\n",
    "                    additional_qual = additional_qual.dropna()\n",
    "                    for row in range(len(additional_qual)):\n",
    "                        add_row(df, coach, \"Add. Qual\", \"\", \"\", \"\", \"\", additional_qual.iloc[row])                     \n",
    "                    \n",
    "def customer_service(question):\n",
    "    global survey\n",
    "    for quest in questions:\n",
    "        if question in quest:\n",
    "            cs_idx = survey.columns.get_loc(quest)\n",
    "            survey = survey.replace({quest:replace_values})\n",
    "            if coaches:\n",
    "                for coach in coaches:\n",
    "                    cs_score = pd.Series(survey[survey[questions[coach_idx]] == coach][questions[cs_idx]], dtype=\"float\")\n",
    "                    add_row(df, coach, \"Customer Service\", \"\", round(cs_score.mean(), 2), \"\", \"\", \"\")                    \n",
    "                    \n",
    "def content_engagement(question):\n",
    "    global survey\n",
    "    for quest in questions:\n",
    "        if question in quest:\n",
    "            ce_idx = survey.columns.get_loc(quest)\n",
    "            survey = survey.replace({quest:replace_values})\n",
    "            if coaches:\n",
    "                for coach in coaches:\n",
    "                    ce_score = pd.Series(survey[survey[questions[coach_idx]] == coach][questions[ce_idx]], dtype=\"float\")\n",
    "                    add_row(df, coach, \"Content Engagement\", \"\", round(ce_score.mean(), 2), \"\", \"\", \"\")\n",
    "                    \n",
    "def activities(question):\n",
    "    global survey\n",
    "    for quest in questions:\n",
    "        if question in quest:\n",
    "            activities_idx = survey.columns.get_loc(quest)\n",
    "            survey = survey.replace({quest:replace_values})\n",
    "            if coaches:\n",
    "                for coach in coaches:\n",
    "                    activities_score = pd.Series(survey[survey[questions[coach_idx]] == coach][questions[activities_idx]], dtype=\"float\")\n",
    "                    activities_score = activities_score.dropna()\n",
    "                    add_row(df, coach, \"Activity Effectiveness\", quest[len(question):], round(activities_score.mean(), 2), \"\", \"\", \"\")                    \n",
    "                    \n",
    "def benchmark(question):\n",
    "    global survey\n",
    "    for quest in questions:\n",
    "        if question in quest and \"Site-visit:\" not in quest and \"Activity:\" not in quest:\n",
    "            benchmark_idx = survey.columns.get_loc(quest)\n",
    "            survey = survey.replace({quest:replace_values})\n",
    "            if coaches:\n",
    "                for coach in coaches:\n",
    "                    benchmark_score = pd.Series(survey[survey[questions[coach_idx]] == coach][questions[benchmark_idx]], dtype=\"float\")\n",
    "                    benchmark_score = benchmark_score.dropna()\n",
    "                    add_row(df, coach, \"Benchmark\", quest[len(question):], round(benchmark_score.mean(), 2), \"\", \"\", \"\")                    \n",
    "                    \n",
    "def useful_qual_comm(question):\n",
    "    for quest in questions:\n",
    "        if question in quest:\n",
    "            useful_qual_idx = survey.columns.get_loc(quest)\n",
    "            if coaches:\n",
    "                for coach in coaches:\n",
    "                    useful_qual = pd.Series(survey[survey[questions[coach_idx]] == coach][questions[useful_qual_idx]], dtype=\"string\")\n",
    "                    useful_qual = useful_qual.dropna()\n",
    "                    for row in range(len(useful_qual)):\n",
    "                        add_row(df, coach, \"Useful Qual\", \"\", \"\", \"\", \"\", useful_qual.iloc[row])  \n",
    "                        \n",
    "def benchmark_qual_comm(question):\n",
    "    for quest in questions:\n",
    "        if question in quest:\n",
    "            benchmark_qual_idx = survey.columns.get_loc(quest)\n",
    "            if coaches:\n",
    "                for coach in coaches:\n",
    "                    benchmark_qual = pd.Series(survey[survey[questions[coach_idx]] == coach][questions[benchmark_qual_idx]], dtype=\"string\")\n",
    "                    benchmark_qual = benchmark_qual.dropna()\n",
    "                    for row in range(len(benchmark_qual)):\n",
    "                        add_row(df, coach, \"Benchmark Qual\", \"\", \"\", \"\", \"\", benchmark_qual.iloc[row]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db87048-da60-413c-b5e3-5c6982c6a251",
   "metadata": {},
   "source": [
    "# enter your survey data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca43a4e-b1e1-4702-9036-a9b5b8923299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the name of the csv you downloaded from Qualtrics (do not add .csv)\n",
    "survey_name = \"\"\n",
    "\n",
    "# enter data in the quotation marks like you would in the spreadsheet, change participants number\n",
    "# leave blank ones as empty quotation marks\n",
    "type_col = \"\"\n",
    "agency_col = \"\"\n",
    "program_col = \"\"\n",
    "cycle_col = \"\"\n",
    "cycle_num_col = \"\"\n",
    "session_name_col = \"\"\n",
    "merged_col = program_col + cycle_col + session_name_col\n",
    "session_num_col = \"\"\n",
    "end_col = \"\"\n",
    "year_col = \"\"\n",
    "quarter_col = \"\"\n",
    "format_col = \"\"\n",
    "participants = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3139459-594b-497a-9ab2-05d9ae68756f",
   "metadata": {},
   "source": [
    "# run the following cell (survey questions will print below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8563b9a-d7d3-4074-9246-4eb239afd615",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = survey_name + \".csv\"\n",
    "survey = pd.read_csv(file, header=1)\n",
    "survey = survey[1:]\n",
    "survey = survey.drop(columns=[\"Start Date\", \"End Date\", \"Response Type\", \"Progress\", \"Duration (in seconds)\",\n",
    "                        \"Finished\", \"Recorded Date\", \"Response ID\", \"Distribution Channel\", \"User Language\"])\n",
    "questions = list(survey.columns)\n",
    "questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281a1c9e-0a54-4307-bc95-95438ff94cf1",
   "metadata": {},
   "source": [
    "# use the survey questions to build the dataframe from the survey data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8f349d-ea30-4a41-907d-6ff602945249",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Do not change the following code, this builds the dataframe in the same structure as the spreadsheet\n",
    "This also is adding the participants and response rate\n",
    "\"\"\"\n",
    "df = pd.DataFrame(columns = [\"Type\", \"Agency\", \"Program\", \"Cycle\", \"Merged\", \"Cycle #\", \"Session Name\", \"Session #\",\n",
    "                             \"End Date\", \"Year\", \"Quarter\", \"Format\", \"Facilitator\", \"Component\", \"Sub Component\",\n",
    "                             \"Effectiveness Score\", \"General #\", \"% Score\", \"Qual\"])\n",
    "\n",
    "# adding participants\n",
    "add_row(df, \"\", \"Participant #\", \"\", \"\", participants, \"\", \"\")\n",
    "\n",
    "# adding response rate\n",
    "add_row(df, \"\", \"Response Rate\", \"\", \"\", len(survey), str(int(round(len(survey)/participants, 2) * 100)) + \"%\", \"\")\n",
    "\n",
    "\"\"\"\n",
    "THIS IS WHERE YOU INPUT YOUR CODE TO ADD THE DATA FROM THE SURVEY\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "The following line of code will display the last 15 lines of your dataframe if you want to check your work\n",
    "The survey metadata is in the dataframe but for viewing purposes, you're only seeing the data that changes\n",
    "\"\"\"\n",
    "df[[\"Facilitator\", \"Component\", \"Sub Component\", \"Effectiveness Score\", \"General #\", \"% Score\", \"Qual\"]][-15:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a71170-7bcf-4c85-ba27-4259cb9a04d1",
   "metadata": {},
   "source": [
    "# uncomment this line of code to save the new dataframe as a csv to your working directory\n",
    "to uncomment, delete the pound sign in front of the line of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69362242-c524-4678-92eb-b42c7225b706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the file name but keep the .csv\n",
    "# df.to_csv(\"INSERT_FILE_NAME.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
